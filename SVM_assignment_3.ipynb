{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Support Vector Machines"
      ],
      "metadata": {
        "id": "jqrWqAPBpDCd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLLLRMsypCQg"
      },
      "outputs": [],
      "source": [
        "# Q1: In order to predict house price based on several characteristics, such as location, square footage, number of bedrooms, etc., you are developing an SVM regression model. Which regression metric in this situation would be the best to employ?\n",
        "# For predicting house prices, the best regression metric to employ is Root Mean Squared Error (RMSE).\n",
        "# RMSE provides a measure of how well the predicted values match the actual values by penalizing larger errors more than smaller ones, which is useful for understanding the typical size of the prediction errors in the same units as the target variable (i.e., currency)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2: You have built an SVM regression model and are trying to decide between using MSE or R-squared as your evaluation metric. Which metric would be more appropriate if your goal is to predict the actual price of a house as accurately as possible?\n",
        "# If your goal is to predict the actual price of a house as accurately as possible, Mean Squared Error (MSE) would be more appropriate. MSE provides a direct measure of the average squared difference between the predicted and actual prices, focusing on the prediction accuracy."
      ],
      "metadata": {
        "id": "Z44cV3Txpkm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3: You have a dataset with a significant number of outliers and are trying to select an appropriate regression metric to use with your SVM model. Which metric would be the most appropriate in this scenario?\n",
        "# For a dataset with a significant number of outliers, Mean Absolute Error (MAE) is the most appropriate regression metric.\n",
        "# MAE is less sensitive to outliers compared to MSE and RMSE because it does not square the errors, providing a more robust measure of prediction accuracy in the presence of outliers."
      ],
      "metadata": {
        "id": "dBVlnbbrpkpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4: You have built an SVM regression model using a polynomial kernel and are trying to select the best metric to evaluate its performance. You have calculated both MSE and RMSE and found that both values are very close. Which metric should you choose to use in this case?\n",
        "# When MSE and RMSE values are very close, either metric can be used.\n",
        "# However, Root Mean Squared Error (RMSE) is generally preferred because it is in the same units as the target variable, making it easier to interpret.\n",
        "# RMSE provides a clear understanding of the model's prediction error in terms of the original units."
      ],
      "metadata": {
        "id": "5UIBaKsPrS-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5: You are comparing the performance of different SVM regression models using different kernels (linear, polynomial, and RBF) and are trying to select the best evaluation metric. Which metric would be most appropriate if your goal is to measure how well the model explains the variance in the target variable?\n",
        "#If your goal is to measure how well the model explains the variance in the target variable, R-squared (RÂ²) is the most appropriate evaluation metric.\n",
        "#R-squared indicates the proportion of the variance in the dependent variable that is predictable from the independent variables, providing a measure of the goodness-of-fit of the model.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Load the dataset\n",
        "url = 'https://drive.google.com/uc?id=1Z9oLpmt6IDRNw7IeNcHYTGeJRYypRSC0'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "\n",
        "# Assume 'price' is the target variable and there might be categorical features\n",
        "\n",
        "# Identify numeric and categorical columns\n",
        "numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = data.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Handle categorical data using one-hot encoding\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = data.drop('price', axis=1)\n",
        "y = data['price']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the SVM regression model within a pipeline\n",
        "svr_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', SVR(kernel='rbf'))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "svr_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the testing data\n",
        "y_pred = svr_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f'MSE: {mse:.2f}')\n",
        "print(f'RMSE: {rmse:.2f}')\n",
        "print(f'R-squared: {r2:.2f}')\n",
        "print(f'MAE: {mae:.2f}')\n",
        "\n",
        "# Tune hyperparameters using GridSearchCV\n",
        "param_grid = {\n",
        "    'regressor__C': [0.1, 1, 10, 100],\n",
        "    'regressor__gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'regressor__epsilon': [0.1, 0.2, 0.5, 1.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(svr_pipeline, param_grid, refit=True, cv=5, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(f'Best parameters found: {grid_search.best_params_}')\n",
        "\n",
        "# Train the tuned model on the entire dataset\n",
        "best_svr = grid_search.best_estimator_\n",
        "best_svr.fit(X, y)\n",
        "\n",
        "# Save the trained model to a file\n",
        "joblib.dump(best_svr, 'best_svr_model.pkl')\n",
        "print(\"Model saved to best_svr_model.pkl\")\n",
        "\n",
        "# Bonus: Visualize results\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_test, y=y_pred)\n",
        "plt.xlabel(\"Actual Prices\")\n",
        "plt.ylabel(\"Predicted Prices\")\n",
        "plt.title(\"Actual vs Predicted Prices\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Explanation:\n",
        "# Load the Dataset:\n",
        "\n",
        "# The dataset is loaded from the provided link and stored in a DataFrame.\n",
        "# Splitting the Dataset:\n",
        "\n",
        "# The dataset is split into training and testing sets using train_test_split.\n",
        "# Preprocessing:\n",
        "\n",
        "# Features are scaled using StandardScaler.\n",
        "# Training the SVM Model:\n",
        "\n",
        "# An SVR model with an RBF kernel is instantiated and trained on the training data.\n",
        "# Prediction:\n",
        "\n",
        "# The trained model is used to predict the target values for the testing set.\n",
        "# Evaluation:\n",
        "\n",
        "# The model's performance is evaluated using MSE, RMSE, R-squared, and MAE.\n",
        "# Hyperparameter Tuning:\n",
        "\n",
        "# GridSearchCV is used to find the best hyperparameters for the SVR model.\n",
        "# Training the Best Model:\n",
        "\n",
        "# The best model found by GridSearchCV is retrained on the entire dataset.\n",
        "# Saving the Model:\n",
        "\n",
        "# The trained model is saved to a file using joblib.\n",
        "# Visualization:\n",
        "\n",
        "# A scatter plot is created to visualize the actual vs. predicted prices."
      ],
      "metadata": {
        "id": "wJ3pBwl8rTJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQu5AKpbrTMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "znsxet6HrTQ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}