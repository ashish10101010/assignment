{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble Techniques\n"
      ],
      "metadata": {
        "id": "Y0SkaIVY0YV-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8Pgtm4v0U0-"
      },
      "outputs": [],
      "source": [
        "# Q1. What is Random Forest Regressor?\n",
        "# Random Forest Regressor is a supervised machine learning algorithm that belongs to the family of ensemble methods.\n",
        "# It is used for regression tasks, where the goal is to predict a continuous outcome (numeric value) based on a set of input features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
        "# Random Forest Regressor reduces the risk of overfitting through several mechanisms:\n",
        "\n",
        "# Ensemble of Trees: It builds multiple decision trees during training, where each tree is trained on a random subset of the data (bootstrap samples) and a random subset of the features (feature bagging).\n",
        "# Averaging Predictions: The final prediction is the average (or mean) of the predictions made by individual trees. This averaging process helps to smooth out the predictions and reduce variance, thereby improving the model's ability to generalize to new, unseen data.\n",
        "# Pruning: Although individual decision trees in a Random Forest can still overfit to some extent, the averaging across multiple trees tends to mitigate this effect, resulting in a more robust model."
      ],
      "metadata": {
        "id": "V9rqOtUy0lk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
        "# Random Forest Regressor aggregates predictions by:\n",
        "\n",
        "# Training multiple decision trees independently on different subsets of the data.\n",
        "# Each tree predicts the target variable based on its own set of rules and features.\n",
        "# During prediction, the regressor calculates the average of predictions from all individual trees to produce the final prediction."
      ],
      "metadata": {
        "id": "chL_O0KF0lqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4. What are the hyperparameters of Random Forest Regressor?\n",
        "# Some common hyperparameters of the Random Forest Regressor include:\n",
        "\n",
        "# n_estimators: Number of trees in the forest.\n",
        "# max_depth: Maximum depth of each tree.\n",
        "# min_samples_split: Minimum number of samples required to split an internal node.\n",
        "# min_samples_leaf: Minimum number of samples required to be at a leaf node.\n",
        "# max_features: Number of features to consider when looking for the best split.\n",
        "# bootstrap: Whether bootstrap samples are used when building trees.\n",
        "# random_state: Seed for random number generation (for reproducibility)."
      ],
      "metadata": {
        "id": "4hTtMB4I0luf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
        "# Decision Tree Regressor: It consists of a single decision tree that is grown recursively by splitting nodes based on the best split criterion (e.g., minimizing variance of target variables).\n",
        "# Random Forest Regressor: It consists of an ensemble of decision trees, where each tree is trained independently on a random subset of the data and a random subset of features.\n",
        "#The final prediction in Random Forest Regressor is the average of predictions from all trees"
      ],
      "metadata": {
        "id": "zTf_8f0t0lyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
        "\n",
        "# Advantages:\n",
        "# Handles large datasets with high dimensionality well.\n",
        "# Robust to overfitting due to averaging of multiple trees.\n",
        "# Provides feature importances, which can aid in understanding the importance of different features.\n",
        "\n",
        "# Disadvantages:\n",
        "# Can be computationally expensive to train, especially with large numbers of trees and features.\n",
        "# May not perform well with noisy or outlier-prone data if not properly tuned.\n",
        "# Interpretability can be challenging compared to a single decision tree."
      ],
      "metadata": {
        "id": "7y8Z3so50l1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7. What is the output of Random Forest Regressor?\n",
        "# The output of Random Forest Regressor is a continuous numeric value, which is the predicted target variable (or outcome) for a given set of input features."
      ],
      "metadata": {
        "id": "5XKbyR690l4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8. Can Random Forest Regressor be used for classification tasks?\n",
        "# Yes, Random Forest Regressor is primarily designed for regression tasks, where the target variable is continuous.\n",
        "# However, there is also a variant called Random Forest Classifier that is specifically designed for classification tasks.\n",
        "# The main difference is in how the trees in the forest are used to make predictions:\n",
        "\n",
        "# Random Forest Regressor: Averages predictions from all trees to predict a continuous value.\n",
        "# Random Forest Classifier: Uses majority voting among trees to predict class labels."
      ],
      "metadata": {
        "id": "EzVJUnkW0l7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OTjsI1dy0mBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCNa7_xZ0mEE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}