{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Na√Øve bayes_assignment_2"
      ],
      "metadata": {
        "id": "zSqpMDoSwhQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Difference between Bernoulli Naive Bayes and Multinomial Naive Bayes\n",
        "# Bernoulli Naive Bayes: Assumes binary features (0 or 1) indicating whether a particular term occurs or not in the document. It is suitable for discrete data and typically used for document classification tasks where the presence or absence of a feature matters.\n",
        "\n",
        "# Multinomial Naive Bayes: Deals with discrete counts, where features represent occurrences of events (e.g., word counts in text classification).\n",
        "# It is appropriate when the frequency of occurrences matters rather than just their presence or absence."
      ],
      "metadata": {
        "id": "uBKCf9kTwwNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How Bernoulli Naive Bayes handles missing values\n",
        "# Bernoulli Naive Bayes in scikit-learn treats missing values (NaNs) as zeros in the feature vectors. This means that missing values are considered as the absence of a feature in the document (0"
      ],
      "metadata": {
        "id": "XC4bo5vVwwRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can Gaussian Naive Bayes be used for multi-class classification?\n",
        "# Yes, Gaussian Naive Bayes can be used for multi-class classification. It assumes that features follow a Gaussian distribution, and it calculates the likelihood of each class based on the Gaussian probability density function. It's suitable when features are continuous and can be used for problems with more than two classes."
      ],
      "metadata": {
        "id": "y2lBvxfowwU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5. Assignment: Implementing Naive Bayes Classifiers\n",
        "# Steps to Implement:\n",
        "# Data Preparation:\n",
        "\n",
        "# Download the \"Spambase Data Set\" from the UCI Machine Learning Repository.\n",
        "# Load and preprocess the dataset as needed.\n",
        "# Implement Naive Bayes Classifiers:\n",
        "\n",
        "# Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes using scikit-learn.\n",
        "# Evaluation:\n",
        "\n",
        "# Use 10-fold cross-validation to evaluate each classifier's performance.\n",
        "# Calculate and report the following metrics: Accuracy, Precision, Recall, F1-score.\n",
        "# Discussion:\n",
        "\n",
        "# Discuss the results obtained from each classifier.\n",
        "# Analyze which variant of Naive Bayes performed the best and provide reasons for your observation.\n",
        "# Identify any limitations or challenges observed with Naive Bayes classifiers.\n",
        "# Conclusion:\n",
        "\n",
        "# Summarize the findings from your evaluation.\n",
        "# Provide suggestions for future work or improvements.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the Spambase dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
        "columns = [\n",
        "    f'word_freq_{i}' for i in range(48)\n",
        "] + ['char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total', 'class']\n",
        "\n",
        "data = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Prepare data\n",
        "X = data.drop('class', axis=1)\n",
        "y = data['class']\n",
        "\n",
        "# Initialize classifiers\n",
        "bernoulli_nb = BernoulliNB()\n",
        "multinomial_nb = MultinomialNB()\n",
        "gaussian_nb = GaussianNB()\n",
        "\n",
        "# Function to evaluate a classifier using cross-validation\n",
        "def evaluate_classifier(clf, X, y):\n",
        "    accuracy = cross_val_score(clf, X, y, cv=10, scoring='accuracy').mean()\n",
        "    precision = cross_val_score(clf, X, y, cv=10, scoring='precision').mean()\n",
        "    recall = cross_val_score(clf, X, y, cv=10, scoring='recall').mean()\n",
        "    f1 = cross_val_score(clf, X, y, cv=10, scoring='f1').mean()\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Evaluate each classifier\n",
        "results = {}\n",
        "for clf, name in [(bernoulli_nb, 'Bernoulli Naive Bayes'), (multinomial_nb, 'Multinomial Naive Bayes'), (gaussian_nb, 'Gaussian Naive Bayes')]:\n",
        "    accuracy, precision, recall, f1 = evaluate_classifier(clf, X, y)\n",
        "    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}\n",
        "\n",
        "# Print results\n",
        "for clf_name, metrics in results.items():\n",
        "    print(f'{clf_name}:')\n",
        "    for metric, value in metrics.items():\n",
        "        print(f' - {metric}: {value:.4f}')\n",
        "\n",
        "# Discussion and Conclusion would follow based on the results obtained\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucNgTbAowwX2",
        "outputId": "190268b0-8021-49ed-afe3-96a417e0e6c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli Naive Bayes:\n",
            " - Accuracy: 0.8839\n",
            " - Precision: 0.8870\n",
            " - Recall: 0.8152\n",
            " - F1-score: 0.8481\n",
            "Multinomial Naive Bayes:\n",
            " - Accuracy: 0.7863\n",
            " - Precision: 0.7393\n",
            " - Recall: 0.7215\n",
            " - F1-score: 0.7283\n",
            "Gaussian Naive Bayes:\n",
            " - Accuracy: 0.8218\n",
            " - Precision: 0.7104\n",
            " - Recall: 0.9570\n",
            " - F1-score: 0.8131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Discussion and Conclusion:\n",
        "# Discussion: Compare the performance metrics (Accuracy, Precision, Recall, F1-score) across different Naive Bayes classifiers.\n",
        "# Analyze which variant performed the best and discuss possible reasons (e.g., suitability of data characteristics).\n",
        "\n",
        "# Conclusion: Summarize findings from the evaluation, discuss limitations observed (e.g., assumptions of independence in Naive Bayes), and suggest areas for future research or improvement."
      ],
      "metadata": {
        "id": "_8dvwxFCyied"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d9hEzIvjxyHc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2qzFtzIyX6p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}