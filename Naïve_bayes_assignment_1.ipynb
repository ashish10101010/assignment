{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Naïve bayes_assignment_1"
      ],
      "metadata": {
        "id": "zSqpMDoSwhQD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V7UCmo-wbhJ"
      },
      "outputs": [],
      "source": [
        "# Q1. What is Bayes' theorem?\n",
        "# Bayes theorem is a fundamental theorem in probability theory that describes the probability of an event, based on prior knowledge of conditions that might be related to the event.\n",
        "# It is named after the Reverend Thomas Bayes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2. What is the formula for Bayes theorem?\n",
        "# Bayes theorem is expressed mathematically as:\n",
        "# P(A/B)=P(B/A).P(A)/P(B)\n",
        "\n",
        "# Where:\n",
        "# P(A/B) is the posterior probability of event A given that event B has occurred.\n",
        "\n",
        "# P(B/A) is the likelihood or conditional probability of event B given that event A is true.\n",
        "\n",
        "# P(A) and P(B) are the probabilities of observing A and B independently of each other; P(B) is also known as the evidence."
      ],
      "metadata": {
        "id": "uBKCf9kTwwNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3. How is Bayes' theorem used in practice?\n",
        "# Bayes theorem is widely used in fields such as statistics, machine learning, and artificial intelligence for:\n",
        "\n",
        "# Statistical inference: Updating beliefs about the probability of a hypothesis as new evidence becomes available.\n",
        "# Machine learning: Naive Bayes classifiers, Bayesian networks, and Bayesian optimization.\n",
        "# Medical diagnosis: Estimating the probability of a disease given certain symptoms.\n",
        "# Spam filtering: Classifying emails as spam or not based on observed features."
      ],
      "metadata": {
        "id": "XC4bo5vVwwRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
        "# Bayes theorem relates the conditional probability of two events to their marginal probabilities.\n",
        "# It provides a way to calculate the conditional probability of an event A given event B using the reverse conditional probability P(B/A)."
      ],
      "metadata": {
        "id": "y2lBvxfowwU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
        "# The choice of Naive Bayes classifier (Gaussian Naive Bayes, Multinomial Naive Bayes, or Bernoulli Naive Bayes) depends on the nature of the features in your dataset:\n",
        "\n",
        "# Gaussian Naive Bayes: Assumes that numerical features follow a Gaussian (normal) distribution.\n",
        "# Multinomial Naive Bayes: Typically used for discrete counts (e.g., word counts for text classification).\n",
        "# Bernoulli Naive Bayes: Assumes binary or boolean features (e.g., presence or absence of a feature).\n",
        "# Choose the classifier whose assumptions about the distribution of your data best match your actual data characteristics."
      ],
      "metadata": {
        "id": "ucNgTbAowwX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6. Assignment: Naive Bayes Classification\n",
        "# Given data (frequency table)\n",
        "import pandas as pd\n",
        "data = {\n",
        "    'Class': ['A', 'B'],\n",
        "    'X1=1': [3, 2],\n",
        "    'X1=2': [3, 2],\n",
        "    'X1=3': [4, 1],\n",
        "    'X2=1': [4, 2],\n",
        "    'X2=2': [3, 2],\n",
        "    'X2=3': [3, 2],\n",
        "    'X2=4': [3, 3]\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate prior probabilities (assuming equal priors)\n",
        "prior_A = 0.5\n",
        "prior_B = 0.5\n",
        "\n",
        "# Likelihoods\n",
        "likelihood_X1_3_A = df.loc[df['Class'] == 'A', 'X1=3'].values[0] / df.loc[df['Class'] == 'A', 'X1=3'].sum()\n",
        "likelihood_X1_3_B = df.loc[df['Class'] == 'B', 'X1=3'].values[0] / df.loc[df['Class'] == 'B', 'X1=3'].sum()\n",
        "\n",
        "likelihood_X2_4_A = df.loc[df['Class'] == 'A', 'X2=4'].values[0] / df.loc[df['Class'] == 'A', 'X2=4'].sum()\n",
        "likelihood_X2_4_B = df.loc[df['Class'] == 'B', 'X2=4'].values[0] / df.loc[df['Class'] == 'B', 'X2=4'].sum()\n",
        "\n",
        "# Applying Naive Bayes formula\n",
        "posterior_A = prior_A * likelihood_X1_3_A * likelihood_X2_4_A\n",
        "posterior_B = prior_B * likelihood_X1_3_B * likelihood_X2_4_B\n",
        "\n",
        "# Predicting the class\n",
        "predicted_class = 'A' if posterior_A > posterior_B else 'B'\n",
        "\n",
        "print(f\"Predicted class for X1=3, X2=4: {predicted_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gesqt92jwwak",
        "outputId": "4aae0de4-3e94-47f2-cc1e-6da8b8f5ca4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class for X1=3, X2=4: B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation:\n",
        "# Prior Probabilities: P(A)=0.5 and P(B)=0.5, assuming equal priors for classes A and B.\n",
        "# Likelihoods: Calculated from the provided frequency table, representing P(X1=3∣A), P(X2=4∣A),P(X1=3∣B), and P(X2=4∣B).\n",
        "# Posterior Probabilities: Calculated using Bayes theorem considering the prior probabilities and likelihoods.\n",
        "# Prediction: The class with the higher posterior probability is predicted as the class for the new instance with features X1=3 and X2=4."
      ],
      "metadata": {
        "id": "d9hEzIvjxyHc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2qzFtzIyX6p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}