{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble Techniques\n"
      ],
      "metadata": {
        "id": "Y0SkaIVY0YV-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Pgtm4v0U0-",
        "outputId": "6d46576c-9104-4c79-be5d-9d5547fddf81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Random Forest Classifier: 0.9561\n"
          ]
        }
      ],
      "source": [
        "# # Q1. Building a Pipeline for Feature Engineering and Modeling\n",
        "#Load the Breast Cancer Dataset from scikit-learn.\n",
        "# Preprocess Data: Handle missing values (if any), scale numerical features, and encode categorical features (if any).\n",
        "# Feature Selection: Use SelectFromModel to automatically select important features.\n",
        "# Build a Random Forest Classifier: Train the classifier on the selected features.\n",
        "# Evaluate the Model: Use accuracy as the metric to evaluate the classifier's performance.\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Step 2: Preprocess Data\n",
        "# No missing values handling needed for this dataset, but we'll scale the features\n",
        "numeric_features = X.select_dtypes(include=np.number).columns\n",
        "preprocessor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Step 3: Feature Selection using SelectFromModel\n",
        "# Example using RandomForestClassifier as the estimator for feature selection\n",
        "feature_selector = SelectFromModel(RandomForestClassifier(random_state=42))\n",
        "X_selected = feature_selector.fit_transform(X_processed, y)\n",
        "\n",
        "# Step 4: Build a Random Forest Classifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the Model\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of Random Forest Classifier: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation:\n",
        "# Step 1: We load the Breast Cancer dataset using load_breast_cancer() function from scikit-learn. This dataset is already cleaned and formatted nicely, so we can directly work with it.\n",
        "\n",
        "# Step 2: In the preprocessing step, we scale the numerical features using StandardScaler. No missing values are handled here because the dataset is complete.\n",
        "\n",
        "# Step 3: We use SelectFromModel with RandomForestClassifier as the estimator to select important features based on their contribution to the model's performance.\n",
        "\n",
        "# Step 4: We build a Random Forest Classifier and train it on the selected features (X_selected).\n",
        "\n",
        "# Step 5: Finally, we evaluate the model's accuracy on the test set (X_test and y_test)."
      ],
      "metadata": {
        "id": "V9rqOtUy0lk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2)Building a Pipeline with Voting Classifier\n",
        "# In this example, we'll create a pipeline that includes a Voting Classifier with three different classifiers: Logistic Regression, Decision Tree Classifier, and Support Vector Classifier (SVC).\n",
        "\n",
        "# Steps:\n",
        "# Load the Dataset: We'll use the Breast Cancer Wisconsin (Diagnostic) Dataset from scikit-learn, similar to the previous example.\n",
        "\n",
        "# Preprocess Data: Handle missing values (if any), scale numerical features, and encode categorical features (if any).\n",
        "\n",
        "# Build Individual Classifiers: Create instances of Logistic Regression, Decision Tree Classifier, and SVC.\n",
        "\n",
        "# Build a Voting Classifier: Combine the individual classifiers using Voting Classifier.\n",
        "\n",
        "# Train and Evaluate the Model: Train the pipeline on the training set and evaluate its performance on the test set.\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Step 2: Preprocess Data\n",
        "# No missing values handling needed for this dataset, but we'll scale the features\n",
        "numeric_features = X.select_dtypes(include=np.number).columns\n",
        "preprocessor = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Step 3: Build Individual Classifiers\n",
        "logistic_regression = LogisticRegression(random_state=42)\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "svc = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Step 4: Build a Voting Classifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('lr', logistic_regression), ('dt', decision_tree), ('svc', svc)],\n",
        "    voting='hard'  # Use 'hard' voting for classification\n",
        ")\n",
        "\n",
        "# Step 5: Build the Pipeline with the Voting Classifier\n",
        "pipeline_voting = Pipeline([\n",
        "    ('preprocessor', preprocessor),  # Reuse preprocessor from previous example\n",
        "    ('classifier', voting_classifier)\n",
        "])\n",
        "\n",
        "# Step 6: Train-test split and Model Evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline_voting.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred_voting = pipeline_voting.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
        "print(f\"Accuracy of the Voting Classifier: {accuracy_voting:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chL_O0KF0lqs",
        "outputId": "91080427-2bd8-464b-953b-85ced098591c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Voting Classifier: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation:\n",
        "# Step 1: We load the Breast Cancer dataset using load_breast_cancer() function from scikit-learn. This dataset is already cleaned and formatted nicely.\n",
        "\n",
        "# Step 2: In the preprocessing step, we scale the numerical features using StandardScaler. No missing values are handled here because the dataset is complete.\n",
        "\n",
        "# Step 3: We instantiate three individual classifiers: Logistic Regression, Decision Tree Classifier, and SVC with a linear kernel.\n",
        "\n",
        "# Step 4: We build a Voting Classifier (voting_classifier) that includes these three classifiers. Here, we use 'hard' voting to make predictions based on the majority class label predicted by each classifier.\n",
        "\n",
        "# Step 5: We create a pipeline (pipeline_voting) that includes the preprocessing steps and the Voting Classifier.\n",
        "\n",
        "# Step 6: We split the data into training and test sets, fit the pipeline on the training data, predict on the test data, and evaluate the model's accuracy using accuracy_score."
      ],
      "metadata": {
        "id": "4hTtMB4I0luf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zTf_8f0t0lyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7y8Z3so50l1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5XKbyR690l4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EzVJUnkW0l7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OTjsI1dy0mBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LCNa7_xZ0mEE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}