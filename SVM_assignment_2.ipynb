{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Support Vector Machines"
      ],
      "metadata": {
        "id": "jqrWqAPBpDCd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLLLRMsypCQg"
      },
      "outputs": [],
      "source": [
        "# Q1: What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
        "# In machine learning, polynomial functions and kernel functions are related in the context of Support Vector Machines (SVMs) and other kernel-based algorithms.\n",
        "# Kernel functions allow SVMs to perform non-linear classification by implicitly mapping input features into higher-dimensional spaces without explicitly computing the coordinates in that space.\n",
        "# A polynomial kernel is a specific type of kernel function that represents the inner product of input vectors in a polynomial feature space.\n",
        "\n",
        "# The polynomial kernel function is defined as:\n",
        "# K(x,y)=(xTy+c)d\n",
        "\n",
        "# where:\n",
        "# x and y are input feature vectors.\n",
        "# c is a constant term.d is the degree of the polynomial.\n",
        "# The relationship between polynomial functions and kernel functions is that the polynomial kernel implicitly computes the polynomial combinations of input features, enabling the SVM to learn non-linear decision boundaries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2: How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
        "# You can implement an SVM with a polynomial kernel in Python using Scikit-learn as follows:\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into a training set and a testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the data (scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create an instance of the SVC classifier with a polynomial kernel\n",
        "clf = SVC(kernel='poly', degree=3, C=1.0, coef0=1)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHrasmoGpkjz",
        "outputId": "4bfe0608-5a24-4380-af65-80babef2f4c0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3: How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
        "# In Support Vector Regression (SVR), the epsilon parameter (ϵ) defines a margin of tolerance where no penalty is given to errors.\n",
        "# Increasing the value of ϵ means that more data points can lie within this margin without contributing to the loss function.\n",
        "# As a result, increasing ϵ generally leads to fewer support vectors because more data points are within the epsilon-tube and are not considered support vectors.\n",
        "# Conversely, decreasing ϵ makes the model stricter, increasing the number of support vectors."
      ],
      "metadata": {
        "id": "Z44cV3Txpkm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4: How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)?\n",
        "# Kernel Function: The kernel function defines the transformation of the input space. Common kernels include linear, polynomial, and radial basis function (RBF). The choice of kernel affects the model's ability to capture non-linear relationships.\n",
        "\n",
        "# Use linear kernel for linear relationships.\n",
        "# Use polynomial or RBF kernels for non-linear relationships.\n",
        "# C Parameter: The C parameter controls the trade-off between achieving a low error on the training data and minimizing the model complexity. A high value of C aims to classify all training examples correctly but can lead to overfitting. A low value of C allows more misclassifications but can result in a more general model.\n",
        "\n",
        "# Increase C to reduce training errors.\n",
        "# Decrease C to simplify the model and improve generalization.\n",
        "# Epsilon Parameter: The epsilon parameter (ϵ) defines the width of the epsilon-tube within which no penalty is given to errors. A larger ϵ results in fewer support vectors and a more tolerant model, while a smaller ϵ leads to a stricter model with more support vectors.\n",
        "\n",
        "# Increase ϵ to allow more deviation within the epsilon-tube.\n",
        "# Decrease ϵ to make the model stricter.\n",
        "# Gamma Parameter: The gamma parameter (γ) defines the influence of a single training example. High gamma means the model will try to capture the details of each data point, which can lead to overfitting. Low gamma leads to a smoother decision boundary.\n",
        "\n",
        "# Increase γ to make the model more sensitive to the training data.\n",
        "# Decrease γ to make the model more general."
      ],
      "metadata": {
        "id": "dBVlnbbrpkpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5: Assignment\n",
        "# Import the necessary libraries and load the dataset\n",
        "# Split the dataset into training and testing sets\n",
        "# Preprocess the data using any technique of your choice\n",
        "# Create an instance of the SVC classifier and train it on the training data\n",
        "# Use the trained classifier to predict the labels of the testing data\n",
        "# Evaluate the performance of the classifier using any metric of your choice\n",
        "# Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV\n",
        "# Train the tuned classifier on the entire dataset\n",
        "# Save the trained classifier to a file for future use\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# 1. Import the necessary libraries and load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Convert to DataFrame for easier manipulation (optional)\n",
        "data = pd.DataFrame(data=X, columns=iris.feature_names)\n",
        "data['target'] = y\n",
        "\n",
        "# 2. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Preprocess the data using any technique of your choice (e.g., scaling)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 4. Create an instance of the SVC classifier and train it on the training data\n",
        "svc = SVC(kernel='rbf', random_state=42)\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# 5. Use the trained classifier to predict the labels of the testing data\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "# 6. Evaluate the performance of the classifier using any metric of your choice\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1 Score: {f1:.2f}')\n",
        "\n",
        "# 7. Tune the hyperparameters of the SVC classifier using GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(f'Best parameters found: {grid.best_params_}')\n",
        "\n",
        "# 8. Train the tuned classifier on the entire dataset\n",
        "best_svc = grid.best_estimator_\n",
        "best_svc.fit(X, y)\n",
        "\n",
        "# 9. Save the trained classifier to a file for future use\n",
        "joblib.dump(best_svc, 'best_svc_model.pkl')\n",
        "\n",
        "print(\"Model saved to best_svc_model.pkl\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6yYx5HKpk0d",
        "outputId": "4d563fb1-d90b-42c2-ef53-287c03fd2eda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1 Score: 1.00\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.0s\n",
            "Best parameters found: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Model saved to best_svc_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5UIBaKsPrS-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3aISEWlrTCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nYuh0-eZrTGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJ3pBwl8rTJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQu5AKpbrTMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "znsxet6HrTQ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}